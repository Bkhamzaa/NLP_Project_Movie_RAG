# NLP_Project_Movie_RAG
Projet de NLP (Master DSSD) visant √† cr√©er un assistant de recommandation de films utilisant une architecture **RAG (Retrieval-Augmented Generation)**.

## üìå Fonctionnalit√©s
- **Moteur de recherche s√©mantique :** Trouve des films bas√©s sur le sens de la phrase et non juste des mots-cl√©s.
- **Architecture RAG :** Utilise `ChromaDB` pour stocker les vecteurs et `Ollama` pour la g√©n√©ration de texte.
- **Interface Web :** Interface utilisateur interactive r√©alis√©e avec `Streamlit`.
- **Mode Local :** Fonctionne enti√®rement sur CPU sans d√©pendance Cloud (confidentialit√© respect√©e).

## üõ†Ô∏è Stack Technique
- **Langage :** Python 3.9+
- **UI :** Streamlit
- **Vector Store :** ChromaDB
- **Embedding :** sentence-transformers (`all-MiniLM-L6-v2`)
- **LLM :** Ollama (Gemma, Mistral, ou Llama3)

## üöÄ Installation

### 1. Pr√©requis
- Python install√©.
- [Ollama](https://ollama.com/) install√© et lanc√©.

### 2. Cloner le projet


### 3. Installer les d√©pendances
- pip install -r requirements.txt

### 4. T√©l√©charger le mod√®le Ollama
Assurez-vous qu'Ollama tourne, puis t√©l√©chargez un mod√®le l√©ger pour le test :
-ollama pull gemma3:4b  /ou
-ollama pull gemma3:270m

## ‚ñ∂Ô∏è Ex√©cution

***Lancez le serveur Ollama dans un terminal :
- ollama serve

***Lancez l'application Streamlit dans un autre terminal :
- streamlit run app.py
